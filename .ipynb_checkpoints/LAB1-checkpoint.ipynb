{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "f2ab2db2-2ca2-47b6-9b78-3ec012b9741f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from torch.nn.functional import mse_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5b1c72-6d44-4028-ae1d-ebdd7943aa00",
   "metadata": {},
   "source": [
    "# 1 Matrix Factorization Using Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "d46523f2-600a-45c4-a9c8-df4b34ef2274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sgd_factorise(A: torch.Tensor, rank: int, num_epochs=1000, lr=0.01) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    m, n = A.shape[0], A.shape[1]\n",
    "    U = torch.rand(m, rank)\n",
    "    V = torch.rand(n, rank)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for r in range(m): \n",
    "            for c in range(n):\n",
    "                e = A[r,c] - U[r,:] @ V[c,:].t()\n",
    "                U[r, :] = U[r, :] + lr * e * V[c, :]\n",
    "                V[c, :] = V[c, :] + lr * e * U[r, :]\n",
    "    return U, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "5aa165df-565f-4fff-8e3f-8a58ca85c14e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A = torch.tensor([[0.3374, 0.6005, 0.1735],\n",
    "                  [3.3359, 0.0492, 1.8374],\n",
    "                  [2.9407, 0.5301, 2.2620]], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "2362f909-fca6-4a35-9872-67710b78eb52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD reconstruction error:  0.23363153636455536\n"
     ]
    }
   ],
   "source": [
    "U, V = sgd_factorise(A, 2)\n",
    "sgd_loss = mse_loss(A, U@V.t(), reduction='sum')\n",
    "print(\"SGD reconstruction error: \", sgd_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c9fa2e-6eaf-48c2-bc25-e759f82ff551",
   "metadata": {},
   "source": [
    "# 2 Compare your result to truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "81b50ef4-c459-429f-8d15-06956d919409",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD reconstruction loss:  0.12227825820446014 SVD reconstruction loss: 0.12191087752580643\n"
     ]
    }
   ],
   "source": [
    "# SGD Solution \n",
    "U, V = sgd_factorise(A, 2)\n",
    "sgd_loss = mse_loss(A, U@V.t(), reduction='sum')\n",
    "\n",
    "# SVD Solution \n",
    "U, S, Vh = torch.linalg.svd(A)\n",
    "S = torch.diag(S)\n",
    "A_ = U[:, :2] @ S[:2, :2] @ Vh[:2, :]\n",
    "svd_loss = mse_loss(A, A_, reduction='sum')\n",
    "\n",
    "print(\"SGD reconstruction loss: \", sgd_loss.item(), \"SVD reconstruction loss:\", svd_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b9e9de-32d2-427d-abf6-2be20851cf0e",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "The reconstion loss for both SVD and SGD methods are almost identical.\n",
    "\n",
    "\n",
    "$\\hat{D}^* = U \\Sigma V^T$\n",
    "\n",
    "This is proven by the Eckart-Young-Mirsky theorem. It shows that given a matrix $D$ and its low rank approximation computed by \n",
    "SVD $\\hat{D}^*$. The Frobeinus norm of this approximation is equal to the sum of squared eigenvalues of the singular SVD matrix $\\Sigma$.\n",
    "\n",
    "$||D - \\hat{D}^*||_F = \\underset{rand(\\hat{D}) \\leq r}{\\min} ||D - \\hat D ||_F = \\sqrt{(\\sigma_1^2 + \\dots + \\sigma_r^2}$\n",
    "\n",
    "This is the loss used by the SGD method and as it is convex the result converges on the <br>\n",
    "SVD low rank approximation. Provided the step size is chosen appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6282c0a-b38c-4cd2-836a-8547a2816e03",
   "metadata": {},
   "source": [
    "# 3 Matrix Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "f1020c3b-1dce-4b1d-9da2-95fefee46908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sgd_partial_factorise(A: torch.Tensor, M: torch.Tensor, rank: int, num_epochs=1000, lr=0.01) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    m, n = A.shape[0], A.shape[1]\n",
    "    U = torch.rand(m, rank)\n",
    "    V = torch.rand(n, rank)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for r in range(m): \n",
    "            for c in range(n):\n",
    "                if M[r,c] == 1:\n",
    "                    e = A[r,c] - U[r,:] @ V[c,:].t()\n",
    "                    U[r, :] = U[r, :] + lr * e * V[c, :]\n",
    "                    V[c, :] = V[c, :] + lr * e * U[r, :]\n",
    "    return U, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "90924b0b-3d2a-440a-a93f-f1a0869933b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A_partial = torch.tensor([[0.3374, 0.6005, 0.1735],\n",
    "                  [0., 0.0492, 1.8374],\n",
    "                  [2.9407, 0., 2.2620]], dtype=torch.float)\n",
    "\n",
    "M = torch.tensor([[1,1,1],\n",
    "                  [0,1,1],\n",
    "                  [1,0,1]], dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "bc5dfa42-1485-417c-b498-9173704cf89a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD reconstruction error:  1.1923713684082031\n"
     ]
    }
   ],
   "source": [
    "U, V = sgd_partial_factorise(A_partial, M, 2)\n",
    "\n",
    "sgd_loss = mse_loss(A, U@V.t(), reduction='sum')\n",
    "print(\"SGD reconstruction error: \", sgd_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85abca4-d4d3-4569-a23b-13e9a06b7569",
   "metadata": {},
   "source": [
    "## What Does This Tell You ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07942965-0c13-4801-9bbe-ba55810aad88",
   "metadata": {},
   "source": [
    "The Loss is higher when using the mask. This however is to be expected due to information being missing from matrix A_partial. <br>\n",
    "The loss is small and hence shows that it is possible to impute the values for unknown data based on a linear comibination of other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead6d3ef-bf63-49d2-99d0-0e5a394edf63",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4 Movie Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "72769dfa-9125-4c86-a414-988372305200",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A = torch.load('data/lab1/ratings.pt')\n",
    "titles = pd.read_csv('data/lab1/titles.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "f3ffe74a-1ed3-4437-806c-3de2ff6e47cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gd_factorise_masked(A: torch.Tensor, M: torch.Tensor, rank: int, num_epochs: int=1000, lr:float=1e-5) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    U = torch.rand(A.shape[0], rank)\n",
    "    V = torch.rand(A.shape[1], rank)\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        err = (A - U@V.t()) * M\n",
    "        U += lr * err @ V\n",
    "        V += lr * err.t() @ U\n",
    "        \n",
    "    return U, V\n",
    "                                                                                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "47315543-881b-40b9-aa73-55e2e087c41d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "======================== IMPORTANT ======================== \n",
    "\n",
    "No information given regarding mask. Hence;\n",
    "\n",
    "Assumtion: Score of 0. indicates missing value \n",
    "\"\"\"\n",
    "\n",
    "U, V = gd_factorise_masked(A, A.ge(0.0001), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "78b2a984-9379-484e-848c-d0de6ec0ad5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A_ = U@V.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "17d867f6-3de8-4be5-af86-b64f3e074a6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie_index = titles.loc[titles['name']==\"A Beautiful Mind\"].to_numpy()[0,0]\n",
    "user_index = 5\n",
    "\n",
    "loss_values = ((A-A_)**2)\n",
    "unmasked_loss = sum(sum(loss_values*A.ge(0.0001)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "d380f487-2701-4d20-9ba1-ad390a1b073e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5 gives A Beautiful Mind a rating of  3.8575429916381836\n",
      "The sum of unmasked squared errors over the whole matrix is:  3921860.5\n"
     ]
    }
   ],
   "source": [
    "print(\"User 5 gives A Beautiful Mind a rating of \", A_[movie_index, user_index].item())\n",
    "print(\"The sum of unmasked squared errors over the whole matrix is: \", unmasked_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b53ee40-bfd1-4fa1-919a-8bf1eb9dee4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67104984-7b88-4ea3-a88d-17b6bb0d9fac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
