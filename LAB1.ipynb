{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2ab2db2-2ca2-47b6-9b78-3ec012b9741f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from torch.nn.functional import mse_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5b1c72-6d44-4028-ae1d-ebdd7943aa00",
   "metadata": {},
   "source": [
    "# 1 Matrix Factorization Using Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d46523f2-600a-45c4-a9c8-df4b34ef2274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sgd_factorise(A: torch.Tensor, rank: int, num_epochs=1000, lr=0.01) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    m, n = A.shape[0], A.shape[1]\n",
    "    U = torch.rand(m, rank)\n",
    "    V = torch.rand(n, rank)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for r in range(m): \n",
    "            for c in range(n):\n",
    "                e = A[r,c] - U[r,:] @ V[c,:].t()\n",
    "                U[r, :] = U[r, :] + lr * e * V[c, :]\n",
    "                V[c, :] = V[c, :] + lr * e * U[r, :]\n",
    "    return U, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa165df-565f-4fff-8e3f-8a58ca85c14e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A = torch.tensor([[0.3374, 0.6005, 0.1735],\n",
    "                  [3.3359, 0.0492, 1.8374],\n",
    "                  [2.9407, 0.5301, 2.2620]], dtype=torch.float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2362f909-fca6-4a35-9872-67710b78eb52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD reconstruction error:  0.12241275608539581\n"
     ]
    }
   ],
   "source": [
    "U, V = sgd_factorise(A, 2)\n",
    "sgd_loss = mse_loss(A, U@V.t(), reduction='sum')\n",
    "print(\"SGD reconstruction error: \", sgd_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc3a503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2627e-01,  5.3989e-01,  3.5064e-01],\n",
      "        [ 3.2428e+00, -1.4864e-03,  1.9860e+00],\n",
      "        [ 3.0449e+00,  5.8703e-01,  2.0958e+00]]) tensor(0.1224)\n"
     ]
    }
   ],
   "source": [
    "print(U@V.t(), mse_loss(A, U@V.t(), reduction='sum'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c9fa2e-6eaf-48c2-bc25-e759f82ff551",
   "metadata": {},
   "source": [
    "# 2 Compare your result to truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81b50ef4-c459-429f-8d15-06956d919409",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD reconstruction loss:  0.12195731699466705 SVD reconstruction loss: 0.12191080302000046\n"
     ]
    }
   ],
   "source": [
    "# SGD Solution \n",
    "U, V = sgd_factorise(A, 2)\n",
    "sgd_loss = mse_loss(A, U@V.t(), reduction='sum')\n",
    "\n",
    "# SVD Solution \n",
    "U, S, Vh = torch.linalg.svd(A)\n",
    "S = torch.diag(S)\n",
    "A_ = U[:, :2] @ S[:2, :2] @ Vh[:2, :]\n",
    "svd_loss = mse_loss(A, A_, reduction='sum')\n",
    "l = (A-A_)**2\n",
    "l = l.sum()\n",
    "\n",
    "print(\"SGD reconstruction loss: \", sgd_loss.item(), \"SVD reconstruction loss:\", svd_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc645c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3492)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f48c22bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3497427626127523"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(0.12232)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b9e9de-32d2-427d-abf6-2be20851cf0e",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "\n",
    "The best rank-k approximation to D in the spectral norm, is given by <br>\n",
    "\n",
    "$ D_k^* := \\sum^k_{i=1} \\sigma_i, u_i, v_i^T $ <br>\n",
    "\n",
    "The Eckart-Young-Mirsky theorm shows that the frobenius norm of the reconstruction error is equal to the square root of the sum of unexplained variances in the singular value matrix. As the frobenious norm is the function minimized by sgd the reconstruction error should be equal to this unexplained variance.\n",
    "\n",
    "$||D - \\hat{D}*||_F = \\underset{rank(\\hat{D} \\leq r)}{min}||D - \\hat{D}||_F = \\sqrt{\\sigma_1^2 + ... + \\sigma_r^2} $\n",
    "\n",
    "given that $\\Sigma$ is;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2351aae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.3339, 0.0000, 0.0000],\n",
       "        [0.0000, 0.6959, 0.0000],\n",
       "        [0.0000, 0.0000, 0.3492]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87569b6d",
   "metadata": {},
   "source": [
    "$\\sqrt{\\sigma_1^2 + ... + \\sigma_r^2} = 0.3492$ <br>\n",
    "\n",
    "The loss function used for sgd solution was the square of the frobenius norm and hence the square root of sgd_loss $\\sqrt{0.1219}$ returns the third eigenvalue (0.3492) thus reaching the global minimum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6282c0a-b38c-4cd2-836a-8547a2816e03",
   "metadata": {},
   "source": [
    "# 3 Matrix Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1020c3b-1dce-4b1d-9da2-95fefee46908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sgd_partial_factorise(A: torch.Tensor, M: torch.Tensor, rank: int, num_epochs=1000, lr=0.01) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    m, n = A.shape[0], A.shape[1]\n",
    "    U = torch.rand(m, rank)\n",
    "    V = torch.rand(n, rank)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for r in range(m): \n",
    "            for c in range(n):\n",
    "                if M[r,c] == 1:\n",
    "                    e = A[r,c] - U[r,:] @ V[c,:].t()\n",
    "                    U[r, :] = U[r, :] + lr * e * V[c, :]\n",
    "                    V[c, :] = V[c, :] + lr * e * U[r, :]\n",
    "    return U, V\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90924b0b-3d2a-440a-a93f-f1a0869933b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A_partial = torch.tensor([[0.3374, 0.6005, 0.1735],\n",
    "                  [0., 0.0492, 1.8374],\n",
    "                  [2.9407, 0., 2.2620]], dtype=torch.float)\n",
    "\n",
    "M = torch.tensor([[1,1,1],\n",
    "                  [0,1,1],\n",
    "                  [1,0,1]], dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc5dfa42-1485-417c-b498-9173704cf89a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3869, 0.5572, 0.1269],\n",
      "        [1.9816, 0.0472, 1.8302],\n",
      "        [2.9284, 1.0882, 2.2763]]) SGD reconstruction error:  2.152406930923462\n"
     ]
    }
   ],
   "source": [
    "U, V = sgd_partial_factorise(A_partial, M, 2)\n",
    "sgd_loss = mse_loss(A, U@V.t(), reduction='sum')\n",
    "print(U@V.t(), \"SGD reconstruction error: \", sgd_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85abca4-d4d3-4569-a23b-13e9a06b7569",
   "metadata": {},
   "source": [
    "## What Does This Tell You ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07942965-0c13-4801-9bbe-ba55810aad88",
   "metadata": {},
   "source": [
    "The Loss is higher when using the mask. This however is to be expected due to information being missing from matrix A_partial. The loss is small and hence shows that it is possible to impute the values for unknown data based on a linear comibination of other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead6d3ef-bf63-49d2-99d0-0e5a394edf63",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4 Movie Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72769dfa-9125-4c86-a414-988372305200",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A = torch.load('data/lab1/ratings.pt')\n",
    "titles = pd.read_csv('data/lab1/titles.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3ffe74a-1ed3-4437-806c-3de2ff6e47cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gd_factorise_masked(A: torch.Tensor, M: torch.Tensor, rank: int, num_epochs: int=1000, lr:float=1e-5) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    U = torch.rand(A.shape[0], rank)\n",
    "    V = torch.rand(A.shape[1], rank)\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        err = (A - U@V.t()) * M\n",
    "        U += lr * err @ V\n",
    "        V += lr * err.t() @ U\n",
    "        \n",
    "    return U, V\n",
    "                                                                                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47315543-881b-40b9-aa73-55e2e087c41d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "======================== IMPORTANT ======================== \n",
    "\n",
    "No information given regarding mask. Hence;\n",
    "\n",
    "Assumtion: Score of 0. indicates missing value \n",
    "\"\"\"\n",
    "U, V = gd_factorise_masked(A, A.ge(0.0001), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78b2a984-9379-484e-848c-d0de6ec0ad5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A_ = U@V.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "17d867f6-3de8-4be5-af86-b64f3e074a6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie_index = titles.loc[titles['name']==\"A Beautiful Mind\"].to_numpy()[0,0]\n",
    "user_index = 4\n",
    "\n",
    "loss_values = ((A-A_)**2)\n",
    "unmasked_loss = sum(sum(loss_values*A.ge(0.0001)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d380f487-2701-4d20-9ba1-ad390a1b073e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5 gives A Beautiful Mind a rating of  3.40004563331604\n",
      "The sum of unmasked squared errors over the whole matrix is:  3935211.0\n"
     ]
    }
   ],
   "source": [
    "print(\"User 5 gives A Beautiful Mind a rating of \", A_[movie_index, user_index].item())\n",
    "print(\"The sum of unmasked squared errors over the whole matrix is: \", unmasked_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b53ee40-bfd1-4fa1-919a-8bf1eb9dee4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67104984-7b88-4ea3-a88d-17b6bb0d9fac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
